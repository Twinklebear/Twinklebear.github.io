---
layout: page
title: "CS 6620 Fall 2014 - Project 11"
description: ""
---
{% include JB/setup %}

<div class="col-lg-12 col-md-12">
	<h4>Comparison of gamma corrected and uncorrected images: 00:41:54</h4>
	<p>
	I ended up playing with gamma correction and having it implemented before it got bumped
	to the next project so I put together a comparison. The gamma correction is done by
	converting the linear RGB values the
	render is computed with to sRGB values, since the sRGB color space includes a gamma correction
	term and is a common and well supported color space. The left (brighter) is the corrected image, the right
	is uncorrected. Both images were rendered with path tracing and adaptive sampling with a min 128
	and max of 1024 samples per pixel.
	<br />
	The scene uses the ordered polymesh version of
	<a href="http://www.headus.com.au/samples/killeroo/">Killeroo</a> and the high res
	Utah teapot. The Killeroo model is using a measured brass material from the
	<a href="http://www.merl.com/brdf/">MERL BRDF Database</a> and the sphere uses a measured gold material
	from <a href="https://github.com/mmp/pbrt-v2">PBRT's material spd files</a>.
	</p>
	<div class="row">
		<div class="col-lg-6 col-md-6" style="text-align:center">
			<a href="/courses/cs6620/prj11_killeroo_correct.png">
				<img src="/courses/cs6620/prj11_killeroo_correct.png" class="img-fluid">
			</a>
		</div>
		<div class="col-lg-6 col-md-6" style="text-align:center">
			<a href="/courses/cs6620/prj11_killeroo_incorrect.png">
				<img src="/courses/cs6620/prj11_killeroo_incorrect.png" class="img-fluid">
			</a>
		</div>
	</div>
	
	<div class="col-lg-12 col-md-12">
		<h4>SmallPT Cornell Box w/ MERL BRDFS: 00:52:35</h4>
		<p>
		Adaptive sampling: min 128, max 1024
		</p>
		<a href="/courses/cs6620/prj11_merl_scene.png">
			<img src="/courses/cs6620/prj11_merl_scene.png" class="img-fluid">
		</a>
		<br />
		<p>
		The MERL scene makes use of the Stanford Dragon and Happy Buddha from the
		<a href="https://graphics.stanford.edu/data/3Dscanrep/">Stanford 3D Scanning Repository</a>. The material
		BRDFS are from the <a href="http://www.merl.com/brdf/">MERL BRDF Database</a> introduced in the paper
		"A Data-Driven Reflectance Model" by Wojciech Matusik, Hanspeter Pfister, Matt Brand and Leonard McMillan.
		The dragon uses the blue acrylic BRDF, the buddha uses the gold metallic paint1 BRDF and the sphere uses
		the red fabric BRDF.
		</p>
	</div>
	<div class="col-lg-12 col-md-12">
		<h4>Fabric SmallPT Cornell Box: 00:45:52</h4>
		<p>
		Adaptive sampling: min 128, max 1024
		</p>
		<a href="/courses/cs6620/prj11_fabric_box.png">
			<img src="/courses/cs6620/prj11_fabric_box.png" class="img-fluid">
		</a>
		<br />
		<p>
		The fabric box scene makes use of the Stanford Bunny from the 
		<a href="https://graphics.stanford.edu/data/3Dscanrep/">Stanford 3D Scanning Repository</a> and the
		high res Utah teapot. The material BRDFS are from the <a href="http://www.merl.com/brdf/">MERL BRDF Database</a>.
		The walls are using the red/white/blue fabric BRDFS, the teapot is using red metallic paint and the bunny is
		using color changing paint2.
		</p>
	</div>
</div>
<div class="col-lg-12 col-md-12">
	<h3>Hardware Used and Other Details</h3>
	<p>
	Render times were measured using <code>std::chrono::high_resolution_clock</code> and only include time to render,
	ie. time to load the scene and write the images to disk is ignored. Images were rendered with path tracing
	using 32 threads with work divided up in 8x8 blocks. A different machine was used to render the images
	since my computer at home was out of commission when rendering the scenes.
	</p>

	CPU: Intel i7 870 @ 2.93 Ghz<br />
	RAM: Forgot to check <br />
	Compiler: gcc 4.9.1 x86_64 (on OpenSUSE)<br />
	Compilation Flags: -m64 -O3 -march=native -flto
	</p>
</div>
</div>

