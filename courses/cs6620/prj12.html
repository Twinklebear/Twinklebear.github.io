---
layout: page
title: "CS 6620 Fall 2014 - Project 12"
description: ""
---
{% include JB/setup %}

<div class="col-lg-12 col-md-12">
	<h4>Comparison of Bidirectional and Forward Path Tracing</h4>
	<p>
	While forward path tracing is much faster it struggles a lot with scenes where the light is occluded,
	such as the one below. The light cover is using measured gold data from
	<a href="https://github.com/mmp/pbrt-v2/tree/master/scenes/spds/metals">PBRT's SPD files</a>.
	</p>
	<div class="row">
	<div class="col-lg-6 col-md-6" style="text-align:center">
		<b>Bidirectional Path Tracing: 00:29:18</b>
		<p>
		Adaptive sampling: min 128, max 512, path lengths: min 3, max 8.
		</p>
		<a href="/courses/cs6620/prj12/cornell_covered_bidir_512.png">
			<img src="/courses/cs6620/prj12/cornell_covered_bidir_512.png" class="img-fluid">
		</a>
	</div>
	<div class="col-lg-6 col-md-6" style="text-align:center">
		<b>Forward Path Tracing: 00:11:05</b>
		<p>
		Adaptive sampling: min 128, max 512, path lengths: min 3, max 8.
		</p>
		<a href="/courses/cs6620/prj12/cornell_covered_fwd_512.png">
			<img src="/courses/cs6620/prj12/cornell_covered_fwd_512.png" class="img-fluid">
		</a>
	</div>
	</div>
	
	<div class="col-lg-12 col-md-12">
		<h4>Cornell Box with covered light: 01:03:14</h4>
		<p>
		Bidirectional path tracing with adaptive sampling: min 128, max 1024, path lengths: min 3, max 8.
		</p>
		<a href="/courses/cs6620/prj12/cornell_covered_bidir_1024.png">
			<img src="/courses/cs6620/prj12/cornell_covered_bidir_1024.png" class="img-fluid">
		</a>
		<br />
	</div>
	<div class="col-lg-12 col-md-12">
		<h4>Tea Time for Test Models: 00:23:01</h4>
		<p>
		Adaptive sampling: min 128, max 1024, path lengths: min 3, max 8
		</p>
		<a href="/courses/cs6620/prj12/teatime.png">
			<img src="/courses/cs6620/prj12/teatime.png" class="img-fluid">
		</a>
		<br />
		<p>
		The tea time scene makes use of the Stanford Armadillo and Bunny from the 
		<a href="https://graphics.stanford.edu/data/3Dscanrep/">Stanford 3D Scanning Repository</a>,
		the smoothed version of the
		<a href="http://dcgi.felk.cvut.cz/cgg/eg07/index.php?page=dragon">EuroGraphics 2007 Phlegmatic Dragon</a> and the
		high res Utah teapot. The Armadillo is using the two layer silver measured BRDF from the
		<a href="http://www.merl.com/brdf/">MERL BRDF Database</a> introduced in the paper
		"A Data-Driven Reflectance Model" by Wojciech Matusik, Hanspeter Pfister, Matt Brand and Leonard McMillan.
	   	The teapot is using measured copper data from
		<a href="https://github.com/mmp/pbrt-v2/tree/master/scenes/spds/metals">PBRT's SPD files</a>.
		</p>
	</div>
	<div class="col-lg-12 col-md-12">
		<h4>SmallPT Cornell Box with MERL BRDFs: 00:35:36</h4>
		<p>
		Adaptive sampling: min 128, max 1024, path lengths: min 3, max 8
		</p>
		<a href="/courses/cs6620/prj12/cornell_merl.png">
			<img src="/courses/cs6620/prj12/cornell_merl.png" class="img-fluid">
		</a>
		<br />
		<p>
		This is the same MERL scene from the last project but with the lighting and model positions improved.
		The MERL scene makes use of the Stanford Dragon and Happy Buddha from the
		<a href="https://graphics.stanford.edu/data/3Dscanrep/">Stanford 3D Scanning Repository</a>. The material
		BRDFs are from the <a href="http://www.merl.com/brdf/">MERL BRDF Database</a>, the dragon uses the blue acrylic BRDF,
		the buddha uses the gold metallic paint BRDF and the sphere uses the red fabric BRDF.
		</p>
	</div>
	<div class="col-lg-12 col-md-12">
		<h4>Caustics Playground: 00:14:58</h4>
		<p>
		Adaptive sampling: min 128, max 512, path lengths: min 3, max 8
		</p>
		<a href="/courses/cs6620/prj12/caustic_playground.png">
			<img src="/courses/cs6620/prj12/caustic_playground.png" class="img-fluid">
		</a>
		<br />
		<p>
		Unfortunately path tracing isn't very well suited to capturing the sharp caustics we'd
		expect to see from light focused through complex geometry like Suzanne so we only get a faint hint of them
		underneath the head. When we implement photon mapping though this render should make for a nice comparison
		as photon mapping is great at capturing caustics. The model is
		a higher poly version of <a href="http://en.wikipedia.org/wiki/Blender_%28software%29#Suzanne">Blender's Suzanne</a>
		created by taking the original Suzanne model and running it through a few rounds of subdivision and smoothing in Blender.
		</p>
	</div>
	<div class="col-lg-12 col-md-12">
		<h4>SmallPT Cornell Box: 00:20:42</h4>
		<p>
		Adaptive sampling: min 128, max 1024, path lengths: min 3, max 8
		</p>
		<a href="/courses/cs6620/prj12/smallpt_cornell.png">
			<img src="/courses/cs6620/prj12/smallpt_cornell.png" class="img-fluid">
		</a>
		<br />
		<p>
		I'm not quite sure the transparency and caustics are correct here.
		The silver ball is using measured silver data from 
		<a href="https://github.com/mmp/pbrt-v2/tree/master/scenes/spds/metals">PBRT's SPD files</a>.
		</p>
		<br />
	</div>
</div>
<div class="col-lg-12 col-md-12">
	<h3>Hardware Used and Other Details</h3>
	<p>
	Render times were measured using <code>std::chrono::high_resolution_clock</code> and only include time to render,
	ie. time to load the scene and write the images to disk is ignored. Unless otherwise mentioned images were
	rendered with forward path tracing using 8 threads with work divided up in 8x8 blocks. My desktop was resurrected
   	with a pretty significant hardware upgrade, which has really improved rendering performance.
	</p>
	CPU: Intel i7-4790k @ 4.0Ghz<br />
	RAM: 16GB 1600Mhz DDR3<br />
	Compiler: gcc 4.9.2 x86_64 (on Windows, built by MinGW-W64 project)<br />
	Compilation Flags: -m64 -O3 -march=native -flto
	</p>
</div>
</div>

