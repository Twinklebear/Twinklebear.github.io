

<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

	<title>Blog</title>
	
    <meta name="author" content="Will Usher">

	<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">

	<!-- Should I be including font-awesome from bootstrap? Or just the 5.0 version? -->
    <!--<script defer src="https://use.fontawesome.com/releases/v5.0.6/js/all.js"></script>-->
    <script defer src="https://kit.fontawesome.com/b56adde3a3.js" crossorigin="anonymous"></script>

	<link href="/assets/molokai.css" rel="stylesheet">
	<link href="/assets/custom.css" rel="stylesheet">
	<link rel="shortcut icon" href="/assets/img/identicon.ico">

</head>
<body>
	<nav class="navbar navbar-expand-md navbar-dark bg-dark static-top">
		<div class="container">
			<a class="navbar-brand" href="/">Will Usher</a>
			<button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse"
				data-target="#navbar_responsive" aria-controls="navbarResponsive" aria-expanded="false"
				aria-label="Toggle navigation">
					<span class="navbar-toggler-icon"></span>
			</button>
			<div class="collapse navbar-collapse" id="navbar_responsive">
				<ul class="navbar-nav mr-auto">
				
				
				  
					
					  
					  
						<li class="nav-item"><a href="/projects" class="nav-link">
							Projects</a></li>
						
					  
					
				  
					
					  
					  
						<li class="nav-item active"><a href="/blog" class="nav-link">
							Blog</a></li>
						
					  
					
				  
					
					  
					  
						<li class="nav-item"><a href="/pages/sdl2" class="nav-link">
							SDL2 Tutorials</a></li>
						
					  
					
				  
					
					  
					  
						<li class="nav-item"><a href="/news" class="nav-link">
							News</a></li>
						
					  
					
				  
					
					  
					  
						<li class="nav-item"><a href="/archive" class="nav-link">
							Archive</a></li>
						
					  
					
				  
				</ul>
			</div><!-- nav.collaps -->
		</div>
	</nav>

	<div class="container content mb-4">
		


<div class="row mt-4 justify-content-center">
	
	<div class="col-9 mb-2">
		<a href="/general/2020/11/15/hw-accel-encoding-rpi4"><h3>Hardware Accelerated Video Encoding on the Raspberry Pi 4 on Ubuntu 20.04 64-bit</h3></a>
		<b>15 Nov 2020</b>
		
<p>I recently picked up a Raspberry Pi 4 8GB model to use for some lightweight server tasks
on my home network. After setting up Pi-Hole, OpenVPN, Plex, and Samba,
I got curious about using it to re-encode some videos I had. The videos are on
an external drive being monitored by Plex and shared on the network by Samba,
and some are quite large since they’re at a (likely unnecessarily) high bitrate.
Trimming them down would help save a bit of space, and gives me an excuse to
play around with Python, FFmpeg, and the Pi’s hardware accelerated video encoder.
In this post, I’ll cover how to get FFmpeg setup to use the Pi 4’s video encoding
hardware on a 64-bit OS and the little encoding manager/dashboard, <a href="https://github.com/Twinklebear/fbed">FBED</a>,
that I put together to monitor the progress of the encoding tasks.</p>



		<a href="/general/2020/11/15/hw-accel-encoding-rpi4">Continue &nbsp;<i class="fa fa-chevron-right" aria-hidden="true"></i></a>
		<div class="mt-2 mx-auto col-8 border-bottom border-secondary">
		</div>
	</div>
	
	<div class="col-9 mb-2">
		<a href="/general/2020/11/13/vis2020-streaming-infrastructure"><h3>The VIS 2020 Streaming Infrastructure</h3></a>
		<b>13 Nov 2020</b>
		
<p>Now that it’s been a bit over a week since VIS 2020 ended I thought I’d
write up some information on the streaming infrastructure
we used during conference. For context, <a href="http://ieeevis.org/year/2020/welcome">IEEE VIS 2020</a>,
like all conferences this year and likely well into the next, was held as a virtual event.
VIS 2020 was “hosted” by the University of Utah, as it was originally planned (pre-COVID) to
be held in Salt Lake City. My advisor was one of the co-chairs, and asked if I’d volunteer
to be on the Technology Committee for VIS 2020. The role of this committee is to manage the technical
aspects of streaming the event. The change to a virtual format brings a lot of challenges,
especially when pivoting later in the planning cycle (the past in-person events are typically
over a year in the making).
However, the virtual format also brings improvements in terms of accessibility, cost to attendees,
environmental impact, and archiving.</p>

<p>This post will be one part technical documentation and one
part reflection. The feedback we received for VIS 2020 was overwhelmingly positive,
and thus I hope that both the technical documentation on how we ran the event
and the reflection on what worked and didn’t are helpful to organizers planning virtual
events through the next year.</p>

<p>Before we begin, I must of course mention that this was not a solo effort.
Alex Bock and Martin Falk were also on the Tech committee and provided valuable
advice about their experience running <a href="https://conferences.eg.org/egev20/">EGEV 2020</a> as a virtual event earlier this year,
which was also well received. We followed the same model for VIS, which aims to keep
the feeling of a live conference while reducing surface area for technical issues.
I must also mention the amazing work done by Alper Sarikaya, Hendrik Strobelt,
Jagoda Walny, and Steve Petruzza on the web committee setting up the
<a href="https://virtual.ieeevis.org/">virtual conference webpage</a>.
The webpage was adapted from <a href="https://github.com/Mini-Conf/Mini-Conf">mini-conf</a>,
originally written by Alexander Rush and Hendrik Strobelt.
Alper <a href="https://alper.datav.is/blog/2020/11/virtual-ieee-vis-website/">has written up a blog post about this</a>,
so I won’t cover it here.
Finally, during the event we had a rotation of about 24 student volunteers
who were responsible for managing the streams and assisting presenters
with technical issues, without whom the event would not have been possible.</p>



		<a href="/general/2020/11/13/vis2020-streaming-infrastructure">Continue &nbsp;<i class="fa fa-chevron-right" aria-hidden="true"></i></a>
		<div class="mt-2 mx-auto col-8 border-bottom border-secondary">
		</div>
	</div>
	
	<div class="col-9 mb-2">
		<a href="/graphics/2020/06/20/0-to-gltf-bind-groups"><h3>From 0 to glTF with WebGPU: Bind Groups</h3></a>
		<b>20 Jun 2020</b>
		
<p>In this second post of the series we’ll learn about Bind Groups,
which let us pass buffers and textures to our shaders.
When writing a renderer, we typically have inputs which do not make sense as vertex
attributes (e.g., transform matrices, material parameters), or simply cannot be passed
as vertex attributes (e.g., textures). Such parameters are instead
passed as uniforms in GLSL terms, or root parameters in HLSL terms.
The application then associates the desired buffers and textures with the
parameters in the shader. In WebGPU, the association of data to parameters is made using Bind Groups.
In this post, we’ll use Bind Groups to pass a uniform buffer containing a view
transform to our vertex shader, allowing us to add camera controls to our triangle
from the previous post.
If you haven’t read the <a href="/graphics/2020/06/15/0-to-gltf-triangle">first post in this series</a>
I recommend reading that first, as we’ll continue directly off the code written there.</p>



		<a href="/graphics/2020/06/20/0-to-gltf-bind-groups">Continue &nbsp;<i class="fa fa-chevron-right" aria-hidden="true"></i></a>
		<div class="mt-2 mx-auto col-8 border-bottom border-secondary">
		</div>
	</div>
	
	<div class="col-9 mb-2">
		<a href="/graphics/2020/06/15/0-to-gltf-triangle"><h3>From 0 to glTF with WebGPU: The First Triangle</h3></a>
		<b>15 Jun 2020</b>
		
<p>WebGPU is a modern graphics API for the web, in development by the
major browser vendors. When compared to WebGL, WebGPU provides more direct
control over the GPU to allow applications to leverage the hardware
more efficiently, similar to Vulkan and DirectX 12.
WebGPU also exposes additional GPU capabilities not available in WebGL, such as compute
shaders and storage buffers, enabling powerful GPU compute applications
to run on the web. As with the switch from OpenGL to Vulkan, WebGPU
exposes more complexity to the user than WebGL, though the API strikes
a good balance between complexity and usability, and overall is quite nice to work with.
In this series, we’ll learn the key aspects of WebGPU from the ground up,
with the goal of going from zero to a basic glTF model renderer.
This post marks our initial step on this journey, where we’ll setup
a WebGPU context and get a triangle on the screen.</p>



		<a href="/graphics/2020/06/15/0-to-gltf-triangle">Continue &nbsp;<i class="fa fa-chevron-right" aria-hidden="true"></i></a>
		<div class="mt-2 mx-auto col-8 border-bottom border-secondary">
		</div>
	</div>
	

	
	<div class="col-12 text-center mb-2">
		<h5>Find older posts in the <a href="/archive">Archive</a></h5>
	</div>
	
</div>


	</div>

	<script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script>
	<!-- Do I actually need popper ? -->
	<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
	<script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>
	
</body>
</html>



